\chapter{Evaluation}
\label{eval}
This chapter discusses the evaluations that were carried out on the project.  In particular, it discusses the approaches that were taken, the results that were collected and the conclusions that can be drawn from the results, including future work for both the evaluations and the product.

It was necessary to perform evaluations with the assistance of people who were not directly involved with the project because an insider might not be able to provide a completely impartial examination of the system.

\section{General Approach}
The evaluation took two forms: firstly, a basic usability evaluation, focussing on a single user's interactions with the system; and secondly, an extended evaluation, examining the positive points and shortcomings of the system when multiple users were working with the system.

It was hoped that a sample of users external to the project, with various levels of knowledge of \bibtex and \LaTeX, would participate in the study.  Sampling a range of users was intended to ensure that the evaluation collected a representative spread of opinions on the product for analysis.

As the evaluation would involve other people, the `School of Computing Science Ethics Checklist'\footnote{The signed ethics checklist document is included as an appendix to this document.} was consulted to ensure that the intended evaluation was ethically sound and that it would not put participants at any greater risk than they encounter in their normal working lives.

The evaluations had slightly different environments and execution, which will be discussed within the relevant sections below.  The purpose of the two different evaluations are explained, and results are included with each of them.

\section{Basic Usability Evaluation}
The basic usability evaluation is based around the points raised in the background survey (Chapter \ref{backgrnd}).  Recall that the examination criteria in the background survey were centred around the \gls{ui} to the system, the features of the system and how fault tolerant and robust the system was.

\subsection{Environment}
The participant sat at a desk on an adjustable-height chair in a well-lit, quiet room at a comfortable temperature.	 Room 620 in the Boyd-Orr Building was the location for some of the experiments, others took place in the participant's office and some took place at the home of the developer.  The location and atmosphere of evaluations are mentioned to draw attention to the developer's conscious decision not to hold evaluations in an environment that was any more stressful, uncomfortable, abnormal or otherwise difficult than daily working conditions.

\subsection{Execution}
The following terminology is used consistently throughout this section: the `participant' means a volunteer who participated in an evaluation of the system and the `host' means the person who was running the evaluation; in all cases, the host was the developer of the system.

Evaluations were structured as follows:
\begin{enumerate}
	\item The host presented the participant with introduction script;\footnote{Introduction and debrief scripts are included as appendices to this document}
	\item The participant read the introduction script;
	\item The host asked the participant to verbally confirm that they agreed to take part in the evaluation;
	\item The participant agreed to take part;
	\item The participant was asked to familiarise themselves with the system by using the site for as long as they wished, and was encouraged to ask questions of the host;
	\item The participant told the host that they were ready to proceed;
	\item The host cleared the system and presented the participant with the task list\footnote{The task list is included as an appendix} and observed the participant, noting any points raised while performing tasks\footnote{The \gls{url} given to participants for import pointed to a search across the \gls{acm} library: \url{http://toms.acm.org/Volumes/V37.html?searchterm=bibtex}};
	\item The participant told the host that they had completed the task list;
	\item The host gave the participant a questionnaire, which they filled in. Notes taken by the host on the participant's behalf were given to them to remind them of things they had mentioned;
	\item The participant gave the host the completed questionnaire, which was put into an opaque folder in a random order, to help preserve participants' anonymity;
	\item The host gave the participant the debrief script;
	\item The participant took a note of the email addresses provided and was given a final chance to ask questions during the evaluation;
	\item The host thanked the participant for their time.
\end{enumerate}

While the participant was performing tasks, the host noted relevant points that the participant raised.  This was done in an attempt to help the participant to focus on the task at hand, rather than leaving the participant to recall the comments they made; it also allowed the host to gain a better insight into any difficulties encountered by the participant.

\subsection{Results}
Tabulate results from the evaluations and go on to analyse the results.

\subsection{Analysis}
Sample of users - some CS students targeted, Physics/Astronomy students, staff and users who don't have academic knowledge - relevant point? why use them? Worth mentioning at all?

\subsection{Improvements Made}

\section{Extended Usability Evaluation}
The second type of usability evaluation was aimed at testing the multi-user functions of the system, in particular the effectiveness of the system to keep users up to date with what has happened. 

\subsection{Environment}
A single session was held in room 620 of the Boyd-Orr Building, under the same conditions as the basic evaluation previous to it.

\subsection{Execution}
The execution involved participants

\subsection{Results}
\subsection{Analysis}

\subsection{Improvements Made}

\section{Summary of Evaluations}

\subsection{Potential Improvements to Evaluations}
